# AgentInterface Architecture

**The canonical pipeline for AI agents → UI components.**

## Design Principles

### Separation of Concerns
- **Agent Reasoning** ≠ **UI Formatting**
- Agents think, reason, use tools → AgentInterface handles UI
- Zero pollution of agent logic with UI concerns

### Zero Integration Friction  
- No system prompt modification required
- No agent framework changes needed
- Universal compatibility via clean wrapper pattern

### Protocol Decoupling
- Shaper LLM handles UI decisions independently
- Agent stays focused on domain reasoning
- UI formatting happens post-reasoning

## The Flow

1. **Frontend Components** → React components exist (`<Card>`, `<Timeline>`, etc.)

2. **Autodiscovery** → `discover.js` scans TypeScript files → `ai.json` registry

3. **Protocol Generation** → `ai.protocol()` reads registry → LLM instructions

4. **Agent Response** → Agent generates natural text: "Here are 3 insights about AI..."

5. **Post-Processing** → `ai.shape(text, context, llm)` transforms text → `{"type": "insights", "data": {...}}`

6. **Frontend Rendering** → Renderer takes JSON → `<InsightsComponent>`

7. **User Interaction** → User clicks button → `ai.interactive()` sends callback to agent

## Integration Pattern

### Universal Agent Wrapper
```python
# User keeps their agent pure - any framework
agent = LangchainAgent() | AutogenAgent() | CustomAgent()

# We wrap with UI capabilities
ui_agent = ai.interactive(agent)

# Everything just works
response = await ui_agent.run("Analyze data")
# → Agent thinks normally (unchanged)
# → Shaper LLM picks components  
# → Beautiful UI rendered
```

### Developer Experience
```python
# Debugging/verification
print(ai.protocol())  # See available components

# Component filtering  
ai.enable_only(['card', 'timeline'])  # Custom selection

# Custom components
# Add your .tsx files → autodiscovery finds them automatically
```

## The Components

### Python SDK
- `ai.protocol()` → LLM format instructions from component registry (debugging)
- `ai.shape(text, context, llm)` → Transform agent text into component JSON (post-processing)
- `ai.interactive(agent)` → Universal agent wrapper with UI capabilities

### TypeScript SDK  
- `<Card>`, `<Timeline>` → Direct component usage (shadcn style)
- `<AIPRenderer>` → JSON to React component rendering for chat UIs
- `discover.js` → Autodiscovery script that generates `ai.json`

### Registry System
- `ai.json` → Cross-language component registry
- Generated by TypeScript autodiscovery
- Consumed by Python for protocol generation
- Consumed by TypeScript for rendering

## The Ultimate Wrapper Vision

### Single Universal Interface
```python
# Any existing agent - zero changes required
agent = LangchainAgent() | CogencyAgent() | AutogenAgent()

# Single wrapper handles everything
ui_agent = ai.interactive(agent)

# Everything just works
response = await ui_agent.run("Analyze this")
# → Agent reasons (unchanged)
# → Shaper LLM transforms output to JSON
# → Frontend renders components  
# → User clicks → Callbacks to agent
```

### Developer Control
```python
# Debugging - see what components are available
print(ai.protocol())

# Component filtering - enable only what you want
ai.enable_only(['card', 'timeline', 'insights'])

# Custom components - just add .tsx files, autodiscovery finds them
```

### LLM Strategy
**Separate Shaper LLM** (canonical choice)
- Agent LLM → Context/reasoning (domain logic)
- Shaper LLM → Context → AIP JSON (UI formatting)
- **PRO**: Perfect separation, universal compatibility, agent stays clean
- **CON**: Extra LLM call (acceptable for perfect decoupling)

### Agent Role Evolution
**Traditional Agent**: Question → Response (end-to-end)
**Wrapped Agent**: Question → Context/Data (reasoning only)
**Shaper**: Context → AIP JSON (presentation only)

The inner agent becomes a **context compiler** - gathering, reasoning, retrieving data. The wrapper handles response formatting.

## Zero Integration Friction

No system prompt changes. No agent modifications. No protocol injection.

**Universal wrapper + Separate formatting = Support for any agent framework.**

## The Distinction

**Interactive Wrapper**: Universal agent interface
- Input: User clicks/interactions → Agent messages  
- Output: Agent responses → Shaper → JSON components

**Protocol**: Debugging/verification tool
- Purpose: See available components, enable custom filtering
- Not injected into agent reasoning cycle

**Canonical. Universal. Zero ceremony.**

## Critical Design Decisions

### Function Naming: ai() vs aip()
**Decision: `ai()`** - Claim the agent interface namespace
- Library is `agentinterface` → `from agentinterface import ai` is canonical
- Following shadcn pattern: they claimed `components/ui`, we claim `components/ai`  
- Bold but justified: if we become defacto standard, prophetic genius
- `ai()` is the system, AIP is the internal protocol

### Wrapper Architecture  
```python
# Canonical wrapper function
ui_agent = ai(
    agent=my_langchain_agent,    # Any existing agent
    llm=my_openai_model,         # For shaping LLM  
    components=['card', 'timeline']  # Optional filtering
)
```

### Agent Role Evolution
**Traditional**: Agent generates complete responses
**Context Compiler Pattern**: Agent generates context/data, wrapper handles presentation
- Agent → Context compiler (reasoning, data gathering)
- Wrapper → Presentation layer (UI formatting)
- Perfect separation of concerns

### Callback Protocol Design
**Agent→UI Protocol**: AIP JSON format
```json
{"type": "card", "data": {"title": "...", "content": "..."}}
```

**UI→Agent Protocol**: TBD - Two options:
- **Raw text**: `"Tell me more about item 3"` (simple)
- **Structured**: `{"action": "expand", "target": "item_3", "context": {...}}` (powerful)

### Zero Integration Friction Philosophy
- No system prompt modification required
- No agent framework changes needed  
- No protocol injection into reasoning cycle
- Universal wrapper pattern supports any agent framework
- Separate shaper LLM maintains clean separation

### Registry Strategy
- **Autodiscovery**: `discover.js` scans TypeScript → generates `ai.json`
- **Cross-language**: Python reads `ai.json` for protocol, TypeScript reads for rendering
- **No manual registration**: Components just export, autodiscovery finds them
- **Component filtering**: Users choose which components to enable

## The Vision

**We're not building a library. We're defining how agent GUIs should work.**

Under 1,000 lines. Zero ceremony. Universal compatibility.

While others build enterprise solutions, we build the canonical standard.